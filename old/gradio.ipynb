{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\dev\\ai_hack\\.venv\\Lib\\site-packages\\kornia\\feature\\lightglue.py:44: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @torch.cuda.amp.custom_fwd(cast_inputs=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import kornia as K\n",
    "import kornia.feature as KF\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from kornia_moons.viz import draw_LAF_matches\n",
    "from kornia.feature import LoFTR, LightGlue\n",
    "import plotly.graph_objects as go\n",
    "import gradio as gr\n",
    "\n",
    "import open3d as o3d\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "device = K.utils.get_cuda_or_mps_device_if_available()\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(data):\n",
    "\n",
    "    Q1 = np.percentile(data, 25)\n",
    "    Q3 = np.percentile(data, 75)\n",
    "    IQR = Q3 - Q1\n",
    "    up_thresh = Q3 + 1.5 * IQR\n",
    "    under_thresh = Q1 - 1.5 * IQR\n",
    "    indexes_up = np.where(data > up_thresh)[0]\n",
    "    indexes_under = np.where(data < under_thresh)[0]\n",
    "\n",
    "    return np.concatenate((indexes_under, indexes_up))\n",
    "\n",
    "def add_intermediate_points(mkpts0, mkpts1):\n",
    "  \"\"\"\n",
    "  Takes 3 near points (near by coordinates, not position in array) and places\n",
    "  one more between them for both arrays.\n",
    "\n",
    "  Args:\n",
    "    mkpts0: Array of keypoints for image 1.\n",
    "    mkpts1: Array of keypoints for image 2.\n",
    "\n",
    "  Returns:\n",
    "    Updated arrays mkpts0 and mkpts1 with added intermediate points.\n",
    "  \"\"\"\n",
    "\n",
    "  distances = np.linalg.norm(mkpts0[:, None, :] - mkpts0[None, :, :], axis=2)\n",
    "  near_indices = np.argwhere(distances < 10)  \n",
    "\n",
    "  # Select 3 near points\n",
    "  if len(near_indices) >= 3:\n",
    "    idx1, idx2 = near_indices[0][:2]\n",
    "    pt1 = mkpts0[idx1]\n",
    "    pt2 = mkpts0[idx2]\n",
    "    pt3 = mkpts0[near_indices[1][1]]\n",
    "\n",
    "    # Calculate intermediate point\n",
    "    new_pt = (pt1 + pt2 + pt3) / 3\n",
    "\n",
    "    # Add the new point to mkpts0\n",
    "    mkpts0 = np.vstack([mkpts0, new_pt])\n",
    "\n",
    "    # Repeat for mkpts1\n",
    "    pt1 = mkpts1[idx1]\n",
    "    pt2 = mkpts1[idx2]\n",
    "    pt3 = mkpts1[near_indices[1][1]]\n",
    "    new_pt = (pt1 + pt2 + pt3) / 3\n",
    "    mkpts1 = np.vstack([mkpts1, new_pt])\n",
    "\n",
    "  return mkpts0, mkpts1\n",
    "\n",
    "# Main function for interface\n",
    "def loftr_and_depth(img1, img2, baseline, center_distance, distance_cam2_object, distance_cam1_object):\n",
    "    device = K.utils.get_cuda_or_mps_device_if_available()\n",
    "\n",
    "    img1 = torch.tensor(img1).permute(2, 0, 1).unsqueeze(0).float().to(device) / 255.0\n",
    "    img2 = torch.tensor(img2).permute(2, 0, 1).unsqueeze(0).float().to(device) / 255.0\n",
    "    \n",
    "    img1 = K.geometry.resize(img1, (512, 512), antialias=True)\n",
    "    img2 = K.geometry.resize(img2, (512, 512), antialias=True)\n",
    "\n",
    "    # Feature matching using LoFTR\n",
    "    matcher = LoFTR(pretrained=\"indoor_new\")\n",
    "\n",
    "    input_dict = {\n",
    "        \"image0\": K.color.rgb_to_grayscale(img1),\n",
    "        \"image1\": K.color.rgb_to_grayscale(img2),\n",
    "    }\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        correspondences = matcher(input_dict)\n",
    "\n",
    "    mkpts0 = correspondences[\"keypoints0\"].cpu().numpy()\n",
    "    mkpts1 = correspondences[\"keypoints1\"].cpu().numpy()\n",
    "\n",
    "    Fm, inliers = cv2.findFundamentalMat(mkpts0, mkpts1, cv2.USAC_MAGSAC, 0.5, 0.999, 100000)\n",
    "    inliers = inliers > 0\n",
    "\n",
    "    disparity = np.abs(mkpts0[:, 0] - mkpts1[:, 0])\n",
    "    depth = (baseline * center_distance) / disparity\n",
    "\n",
    "    # Create point cloud\n",
    "    points = []\n",
    "    for i in range(len(mkpts0)):\n",
    "        x = mkpts0[i][0]\n",
    "        y = mkpts0[i][1]\n",
    "        z = depth[i]\n",
    "        points.append([x, y, z])\n",
    "\n",
    "    points = np.array(points)\n",
    "\n",
    "    outliers_indexes = find_outliers(points[:, 2])\n",
    "    points = np.delete(points, outliers_indexes, axis=0)\n",
    "\n",
    "    # Create Open3D point cloud\n",
    "    pcd = o3d.geometry.PointCloud()\n",
    "    pcd.points = o3d.utility.Vector3dVector(points)\n",
    "\n",
    "    # Get the colors from the original images\n",
    "    colors = []\n",
    "    for i in range(len(mkpts0)):\n",
    "        x = int(mkpts0[i][0])\n",
    "        y = int(mkpts0[i][1])\n",
    "        color = img1[0, :, y, x].cpu().numpy()\n",
    "        colors.append(color)\n",
    "\n",
    "    fig = go.Figure(\n",
    "        data=[\n",
    "            go.Scatter3d(\n",
    "                x=points[:, 0],\n",
    "                y=points[:, 1],\n",
    "                z=points[:, 2],\n",
    "                mode=\"markers\",\n",
    "                marker=dict(\n",
    "                    size=3,\n",
    "                    color=colors, \n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Extract x, y, z coordinates\n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    z = points[:, 2] / 1000\n",
    "\n",
    "    # Define grid over x and y\n",
    "    grid_x, grid_y = np.mgrid[x.min():x.max(), y.min():y.max()]  # Adjust range and resolution as needed\n",
    "\n",
    "    # Interpolate z values on the grid\n",
    "    grid_z = griddata((x, y), z, (grid_x, grid_y), method='linear')\n",
    "\n",
    "    fig = go.Figure(data=[go.Surface(x=grid_x, y=grid_y, z=grid_z)])\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\n",
    "    gr.Image(type=\"numpy\", label=\"Изображение 1\"),\n",
    "    gr.Image(type=\"numpy\", label=\"Изображение 2\"),\n",
    "    gr.Number(value=412, label=\"Базовое расстояние (мм)\"),\n",
    "    gr.Number(value=639, label=\"Расстояние до центра (мм)\"),\n",
    "    gr.Number(value=641, label=\"Расстояние от камеры 2 до объекта (мм)\"),\n",
    "    gr.Number(value=660, label=\"Расстояние от камеры 1 до объекта (мм)\"),\n",
    "]\n",
    "\n",
    "outputs = [\n",
    "    gr.Plot(label=\"3D облако точек\"),\n",
    "]\n",
    "\n",
    "description = \"\"\"\n",
    "Загрузите пару изображений и при необходимости настройте параметры, затем нажмите 'Submit' для измерения геометрии.\n",
    "- **Базовое расстояние**: Расстояние между двумя камерами (в мм).\n",
    "- **Расстояние до центра**: Расстояние от центра между камерами до объекта (в мм).\n",
    "- **Расстояние от камеры 2 до объекта**: Расстояние от камеры 2 (левая) до объекта (в мм).\n",
    "- **Расстояние от камеры 1 до объекта**: Расстояние от камеры 1 (правая) до объекта (в мм).\n",
    "\"\"\"\n",
    "\n",
    "title = \"Измерение геометрии на основе стереоизображений\"\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=loftr_and_depth,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    live=False,\n",
    "    title=title,\n",
    "    description=description\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
